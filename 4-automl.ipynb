{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acesso negado: 'C:\\\\Users\\\\lucas\\\\Repos\\\\real-time-process-prediction\\\\venv\\\\Lib\\\\site-packages\\\\~sutil\\\\_psutil_windows.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\lucas\\Repos\\real-time-process-prediction\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install autogluon.tabular[all] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Repos\\real-time-process-prediction\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# AutoML\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/y_train.csv')\n",
    "X_val = pd.read_csv('data/processed/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/y_val.csv')\n",
    "X_test = pd.read_csv('data/processed/X_test.csv')\n",
    "y_test = pd.read_csv('data/processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "valid_set = pd.concat([X_val, y_val], axis=1)\n",
    "test_set = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vazaoVapor</th>\n",
       "      <th>pressaoVapor</th>\n",
       "      <th>temperaturaVapor</th>\n",
       "      <th>cargaVaporTG1</th>\n",
       "      <th>cargaVaporTG2</th>\n",
       "      <th>habilitaTG1</th>\n",
       "      <th>habilitaTG2</th>\n",
       "      <th>consumoEspecificoTG1_1</th>\n",
       "      <th>consumoEspecificoTG1_2</th>\n",
       "      <th>consumoEspecificoTG2_1</th>\n",
       "      <th>consumoEspecificoTG2_2</th>\n",
       "      <th>potenciaGeradaTG1_1</th>\n",
       "      <th>potenciaGeradaTG1_2</th>\n",
       "      <th>potenciaGeradaTG2_1</th>\n",
       "      <th>potenciaGeradaTG2_2</th>\n",
       "      <th>vazaoVaporEscape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376.684774</td>\n",
       "      <td>57.704084</td>\n",
       "      <td>823.608926</td>\n",
       "      <td>187.716124</td>\n",
       "      <td>63.247392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.508188</td>\n",
       "      <td>9.357013</td>\n",
       "      <td>4.639457</td>\n",
       "      <td>11.947866</td>\n",
       "      <td>22.062996</td>\n",
       "      <td>20.061545</td>\n",
       "      <td>13.632499</td>\n",
       "      <td>3.619675</td>\n",
       "      <td>377.273956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283.934340</td>\n",
       "      <td>60.319730</td>\n",
       "      <td>867.005162</td>\n",
       "      <td>205.307873</td>\n",
       "      <td>85.807646</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058899</td>\n",
       "      <td>11.679906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.371380</td>\n",
       "      <td>5.019430</td>\n",
       "      <td>307.311031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>406.481097</td>\n",
       "      <td>61.930230</td>\n",
       "      <td>755.382943</td>\n",
       "      <td>147.415838</td>\n",
       "      <td>104.507646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.841750</td>\n",
       "      <td>8.632192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.305527</td>\n",
       "      <td>17.077451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>370.484139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.502754</td>\n",
       "      <td>60.383351</td>\n",
       "      <td>853.381528</td>\n",
       "      <td>168.249068</td>\n",
       "      <td>58.854856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.458438</td>\n",
       "      <td>9.194291</td>\n",
       "      <td>4.336866</td>\n",
       "      <td>11.990789</td>\n",
       "      <td>22.558217</td>\n",
       "      <td>18.299297</td>\n",
       "      <td>13.570827</td>\n",
       "      <td>3.240392</td>\n",
       "      <td>422.212430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278.490964</td>\n",
       "      <td>63.136766</td>\n",
       "      <td>824.400477</td>\n",
       "      <td>123.498988</td>\n",
       "      <td>110.203105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.579387</td>\n",
       "      <td>7.751438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.673549</td>\n",
       "      <td>15.932396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.498993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vazaoVapor  pressaoVapor  temperaturaVapor  cargaVaporTG1  cargaVaporTG2  \\\n",
       "0  376.684774     57.704084        823.608926     187.716124      63.247392   \n",
       "1  283.934340     60.319730        867.005162     205.307873      85.807646   \n",
       "2  406.481097     61.930230        755.382943     147.415838     104.507646   \n",
       "3  396.502754     60.383351        853.381528     168.249068      58.854856   \n",
       "4  278.490964     63.136766        824.400477     123.498988     110.203105   \n",
       "\n",
       "   habilitaTG1  habilitaTG2  consumoEspecificoTG1_1  consumoEspecificoTG1_2  \\\n",
       "0            1            1                8.508188                9.357013   \n",
       "1            0            1                0.000000                0.000000   \n",
       "2            1            0               15.841750                8.632192   \n",
       "3            1            1                7.458438                9.194291   \n",
       "4            1            0               10.579387                7.751438   \n",
       "\n",
       "   consumoEspecificoTG2_1  consumoEspecificoTG2_2  potenciaGeradaTG1_1  \\\n",
       "0                4.639457               11.947866            22.062996   \n",
       "1                4.058899               11.679906             0.000000   \n",
       "2                0.000000                0.000000             9.305527   \n",
       "3                4.336866               11.990789            22.558217   \n",
       "4                0.000000                0.000000            11.673549   \n",
       "\n",
       "   potenciaGeradaTG1_2  potenciaGeradaTG2_1  potenciaGeradaTG2_2  \\\n",
       "0            20.061545            13.632499             3.619675   \n",
       "1             0.000000            19.371380             5.019430   \n",
       "2            17.077451             0.000000             0.000000   \n",
       "3            18.299297            13.570827             3.240392   \n",
       "4            15.932396             0.000000             0.000000   \n",
       "\n",
       "   vazaoVaporEscape  \n",
       "0        377.273956  \n",
       "1        307.311031  \n",
       "2        370.484139  \n",
       "3        422.212430  \n",
       "4        210.498993  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = TabularDataset(train_set)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['consumoEspecificoTG1_1', 'consumoEspecificoTG1_2',\n",
       "       'consumoEspecificoTG2_1', 'consumoEspecificoTG2_2',\n",
       "       'potenciaGeradaTG1_1', 'potenciaGeradaTG1_2', 'potenciaGeradaTG2_1',\n",
       "       'potenciaGeradaTG2_2', 'vazaoVaporEscape'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumoEspecificoTG1_1',\n",
       " 'consumoEspecificoTG1_2',\n",
       " 'consumoEspecificoTG2_1',\n",
       " 'consumoEspecificoTG2_2',\n",
       " 'potenciaGeradaTG1_1',\n",
       " 'potenciaGeradaTG1_2',\n",
       " 'potenciaGeradaTG2_1',\n",
       " 'potenciaGeradaTG2_2',\n",
       " 'vazaoVaporEscape']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = y_test.columns.tolist()\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel\n",
    "\n",
    "Train a model for each target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor:\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = os.path.join(self.path, \"Predictor_\" + str(label))\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=os.path.join(self.path, self.multi_predictor_file), object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        return load_pkl.load(path=os.path.join(path, cls.multi_predictor_file))\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = ['mean_squared_error','mean_absolute_percentage_error', 'r2', 'symmetric_mean_absolute_percentage_error']  # metrics used to evaluate predictions for each label (optional)\n",
    "save_path = 'agModels'  # specifies folder to store trained models (optional)\n",
    "\n",
    "time_limit = 180  # how many seconds to train the TabularPredictor for each label, set much larger in your applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression',\n",
       " 'regression']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['regression']*len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=target, problem_types=['regression']*len(target),\n",
    "                                        eval_metrics=['symmetric_mean_absolute_percentage_error']*len(target), path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       1.89 GB / 15.69 GB (12.0%)\n",
      "Disk Space Avail:   487.41 GB / 929.98 GB (52.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: consumoEspecificoTG1_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_consumoEspecificoTG1_1\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 7\n",
      "Label Column:       consumoEspecificoTG1_1\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1906.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.84 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2']\n",
      "\t\t('int', [])   : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 5 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2']\n",
      "\t\t('int', ['bool']) : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.38 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.7s of the 179.7s of remaining time.\n",
      "\t-0.6716\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 176.22s of the 176.22s of remaining time.\n",
      "\t-0.6726\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 175.64s of the 175.64s of remaining time.\n",
      "\t-0.5001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t2.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 172.64s of the 172.64s of remaining time.\n",
      "\t-0.4932\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 171.2s of the 171.19s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 127 due to low memory. Expected memory usage reduced from 35.31% -> 15.0% of available memory...\n",
      "\t-0.001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t17.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 152.97s of the 152.97s of remaining time.\n",
      "\t-0.4958\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t5.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 147.89s of the 147.89s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 117 due to low memory. Expected memory usage reduced from 38.42% -> 15.0% of available memory...\n",
      "\t-0.0011\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t4.76s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 142.76s of the 142.76s of remaining time.\n",
      "Metric symmetric_mean_absolute_percentage_error is not supported by this model - using mean_squared_error instead\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 23)\n",
      "\t-0.4529\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t139.31s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3.31s of the 3.31s of remaining time.\n",
      "\t-0.492\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t3.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.7s of the -0.21s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.667, 'ExtraTreesMSE': 0.333}\n",
      "\t-0.001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 21396.3 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_consumoEspecificoTG1_1\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       1.87 GB / 15.69 GB (11.9%)\n",
      "Disk Space Avail:   486.85 GB / 929.98 GB (52.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_consumoEspecificoTG1_2\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 8\n",
      "Label Column:       consumoEspecificoTG1_2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1904.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.82 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: consumoEspecificoTG1_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 6 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.36 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.67s of the 179.67s of remaining time.\n",
      "\t-0.0902\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.01s of the 179.01s of remaining time.\n",
      "\t-0.0889\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 178.39s of the 178.39s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000480312\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490974\n",
      "[2000]\tvalid_set's l2: 0.000342494\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490865\n",
      "[3000]\tvalid_set's l2: 0.000277179\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490809\n",
      "[4000]\tvalid_set's l2: 0.000236831\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490769\n",
      "[5000]\tvalid_set's l2: 0.000210082\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490742\n",
      "[6000]\tvalid_set's l2: 0.000193779\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490725\n",
      "[7000]\tvalid_set's l2: 0.000179572\tvalid_set's symmetric_mean_absolute_percentage_error: -0.49071\n",
      "[8000]\tvalid_set's l2: 0.000167346\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490695\n",
      "[9000]\tvalid_set's l2: 0.000157995\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490684\n",
      "[10000]\tvalid_set's l2: 0.000150558\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4907\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t49.66s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 127.99s of the 127.99s of remaining time.\n",
      "\t-0.4905\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 126.33s of the 126.33s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 141 due to low memory. Expected memory usage reduced from 31.88% -> 15.0% of available memory...\n",
      "\t-0.0\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t15.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 110.29s of the 110.29s of remaining time.\n",
      "\t-0.4905\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t35.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 74.96s of the 74.96s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 146 due to low memory. Expected memory usage reduced from 30.69% -> 15.0% of available memory...\n",
      "\t-0.0\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t2.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 71.82s of the 71.82s of remaining time.\n",
      "Metric symmetric_mean_absolute_percentage_error is not supported by this model - using mean_squared_error instead\n",
      "\t-0.4732\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t54.07s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 17.68s of the 17.68s of remaining time.\n",
      "\t-0.4905\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 16.73s of the 16.73s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\t-0.4921\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t16.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.67s of the 0.37s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 179.72s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 55644.4 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_consumoEspecificoTG1_2\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       1.95 GB / 15.69 GB (12.4%)\n",
      "Disk Space Avail:   486.18 GB / 929.98 GB (52.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_consumoEspecificoTG2_1\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 9\n",
      "Label Column:       consumoEspecificoTG2_1\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1992.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: consumoEspecificoTG2_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 7 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 7 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.69s of the 179.69s of remaining time.\n",
      "\t-0.6648\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.97s of the 178.97s of remaining time.\n",
      "\t-0.665\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 178.26s of the 178.26s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.00313708\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504309\n",
      "[2000]\tvalid_set's l2: 0.00192617\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503997\n",
      "[3000]\tvalid_set's l2: 0.00166494\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503877\n",
      "[4000]\tvalid_set's l2: 0.00148643\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503799\n",
      "[5000]\tvalid_set's l2: 0.00136747\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503749\n",
      "[6000]\tvalid_set's l2: 0.00125153\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503709\n",
      "[7000]\tvalid_set's l2: 0.00118974\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503675\n",
      "[8000]\tvalid_set's l2: 0.00115239\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50365\n",
      "[9000]\tvalid_set's l2: 0.00112644\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503631\n",
      "[10000]\tvalid_set's l2: 0.00108274\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5036\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t35.3s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 142.18s of the 142.18s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000915009\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503437\n",
      "[2000]\tvalid_set's l2: 0.00081275\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503342\n",
      "[3000]\tvalid_set's l2: 0.000784595\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503302\n",
      "[4000]\tvalid_set's l2: 0.000767962\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503275\n",
      "[5000]\tvalid_set's l2: 0.000760594\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503261\n",
      "[6000]\tvalid_set's l2: 0.000754163\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503249\n",
      "[7000]\tvalid_set's l2: 0.000747092\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503242\n",
      "[8000]\tvalid_set's l2: 0.000744102\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503238\n",
      "[9000]\tvalid_set's l2: 0.000743808\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503232\n",
      "[10000]\tvalid_set's l2: 0.000742272\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5032\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t34.96s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 106.5s of the 106.5s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 133 due to low memory. Expected memory usage reduced from 33.63% -> 15.0% of available memory...\n",
      "\t-0.0009\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t20.71s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 85.09s of the 85.09s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 6286.\n",
      "\t-0.5032\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t85.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.69s of the -0.31s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0009\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.41s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 41413.5 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_consumoEspecificoTG2_1\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       1.85 GB / 15.69 GB (11.8%)\n",
      "Disk Space Avail:   485.77 GB / 929.98 GB (52.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_consumoEspecificoTG2_2\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 10\n",
      "Label Column:       consumoEspecificoTG2_2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1888.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 19.77 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: consumoEspecificoTG2_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 8 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.5s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.4s of the 179.4s of remaining time.\n",
      "\t-0.4978\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 177.9s of the 177.89s of remaining time.\n",
      "\t-0.4926\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 176.44s of the 176.44s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000672175\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503061\n",
      "[2000]\tvalid_set's l2: 0.000504253\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502995\n",
      "[3000]\tvalid_set's l2: 0.000436228\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502962\n",
      "[4000]\tvalid_set's l2: 0.00038992\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502941\n",
      "[5000]\tvalid_set's l2: 0.000361357\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502928\n",
      "[6000]\tvalid_set's l2: 0.000341676\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502918\n",
      "[7000]\tvalid_set's l2: 0.000326726\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50291\n",
      "[8000]\tvalid_set's l2: 0.000317823\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502905\n",
      "[9000]\tvalid_set's l2: 0.000309254\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502901\n",
      "[10000]\tvalid_set's l2: 0.000303236\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5029\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t43.82s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 131.87s of the 131.87s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000262262\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502865\n",
      "[2000]\tvalid_set's l2: 0.000227465\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50284\n",
      "[3000]\tvalid_set's l2: 0.000213288\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502831\n",
      "[4000]\tvalid_set's l2: 0.000211565\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502827\n",
      "[5000]\tvalid_set's l2: 0.00021242\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502824\n",
      "[6000]\tvalid_set's l2: 0.000211936\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502822\n",
      "[7000]\tvalid_set's l2: 0.0002108\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50282\n",
      "[8000]\tvalid_set's l2: 0.00021141\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50282\n",
      "[9000]\tvalid_set's l2: 0.00021129\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502819\n",
      "[10000]\tvalid_set's l2: 0.000210866\tvalid_set's symmetric_mean_absolute_percentage_error: -0.502818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5028\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t42.49s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 88.69s of the 88.69s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 152 due to low memory. Expected memory usage reduced from 29.54% -> 15.0% of available memory...\n",
      "\t-0.0001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t24.06s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 64.15s of the 64.15s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 5325.\n",
      "\t-0.5029\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t64.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.4s of the -0.22s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 28026.3 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_consumoEspecificoTG2_2\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       2.90 GB / 15.69 GB (18.5%)\n",
      "Disk Space Avail:   485.37 GB / 929.98 GB (52.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_potenciaGeradaTG1_1\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 11\n",
      "Label Column:       potenciaGeradaTG1_1\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2962.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 21.75 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: potenciaGeradaTG1_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 18.29 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.65s of the 179.65s of remaining time.\n",
      "\t-0.0161\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.69s of the 178.69s of remaining time.\n",
      "\t-0.0156\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 177.73s of the 177.72s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.0218848\tvalid_set's symmetric_mean_absolute_percentage_error: -0.493503\n",
      "[2000]\tvalid_set's l2: 0.0160048\tvalid_set's symmetric_mean_absolute_percentage_error: -0.493069\n",
      "[3000]\tvalid_set's l2: 0.0135389\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492852\n",
      "[4000]\tvalid_set's l2: 0.0119433\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492692\n",
      "[5000]\tvalid_set's l2: 0.0108212\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492578\n",
      "[6000]\tvalid_set's l2: 0.00995937\tvalid_set's symmetric_mean_absolute_percentage_error: -0.49247\n",
      "[7000]\tvalid_set's l2: 0.00932663\tvalid_set's symmetric_mean_absolute_percentage_error: -0.49238\n",
      "[8000]\tvalid_set's l2: 0.0088025\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492305\n",
      "[9000]\tvalid_set's l2: 0.00836763\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492238\n",
      "[10000]\tvalid_set's l2: 0.00806131\tvalid_set's symmetric_mean_absolute_percentage_error: -0.492185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4922\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t32.1s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 144.96s of the 144.96s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.00332027\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491602\n",
      "[2000]\tvalid_set's l2: 0.00234167\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491397\n",
      "[3000]\tvalid_set's l2: 0.00197919\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491313\n",
      "[4000]\tvalid_set's l2: 0.0017939\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491266\n",
      "[5000]\tvalid_set's l2: 0.00169352\tvalid_set's symmetric_mean_absolute_percentage_error: -0.49124\n",
      "[6000]\tvalid_set's l2: 0.00162318\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491215\n",
      "[7000]\tvalid_set's l2: 0.00157651\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491203\n",
      "[8000]\tvalid_set's l2: 0.00154604\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491196\n",
      "[9000]\tvalid_set's l2: 0.00151845\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491187\n",
      "[10000]\tvalid_set's l2: 0.00149321\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4912\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t32.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 112.16s of the 112.16s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 211 due to low memory. Expected memory usage reduced from 21.32% -> 15.0% of available memory...\n",
      "\t-0.0005\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t36.83s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 74.49s of the 74.49s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 6407.\n",
      "\t-0.4911\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t74.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.65s of the -0.2s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0005\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.28s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 41742.7 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_potenciaGeradaTG1_1\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       2.87 GB / 15.69 GB (18.3%)\n",
      "Disk Space Avail:   484.79 GB / 929.98 GB (52.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_potenciaGeradaTG1_2\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 12\n",
      "Label Column:       potenciaGeradaTG1_2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2930.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 23.73 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: potenciaGeradaTG1_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 10 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 20.27 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.63s of the 179.63s of remaining time.\n",
      "\t-0.0019\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.57s of the 178.57s of remaining time.\n",
      "\t-0.0018\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 177.47s of the 177.46s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.00296915\tvalid_set's symmetric_mean_absolute_percentage_error: -0.491041\n",
      "[2000]\tvalid_set's l2: 0.00201502\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490928\n",
      "[3000]\tvalid_set's l2: 0.00159726\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490869\n",
      "[4000]\tvalid_set's l2: 0.00132677\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490828\n",
      "[5000]\tvalid_set's l2: 0.00118081\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490802\n",
      "[6000]\tvalid_set's l2: 0.00107298\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490782\n",
      "[7000]\tvalid_set's l2: 0.000983259\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490764\n",
      "[8000]\tvalid_set's l2: 0.000923575\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490751\n",
      "[9000]\tvalid_set's l2: 0.000869037\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490739\n",
      "[10000]\tvalid_set's l2: 0.000830124\tvalid_set's symmetric_mean_absolute_percentage_error: -0.49073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4907\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t35.81s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 140.91s of the 140.91s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000146446\tvalid_set's symmetric_mean_absolute_percentage_error: -0.490465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4905\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t4.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 136.55s of the 136.55s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 213 due to low memory. Expected memory usage reduced from 21.09% -> 15.0% of available memory...\n",
      "\t-0.0\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t36.45s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 99.72s of the 99.72s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 8075.\n",
      "\t-0.4905\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t99.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.63s of the -0.23s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 53921.1 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_potenciaGeradaTG1_2\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       3.01 GB / 15.69 GB (19.2%)\n",
      "Disk Space Avail:   484.22 GB / 929.98 GB (52.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_potenciaGeradaTG2_1\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 13\n",
      "Label Column:       potenciaGeradaTG2_1\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3087.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 25.70 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: potenciaGeradaTG2_1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 11 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 22.24 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.62s of the 179.62s of remaining time.\n",
      "\t-0.0165\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.39s of the 178.38s of remaining time.\n",
      "\t-0.0159\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 177.21s of the 177.2s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.029719\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50614\n",
      "[2000]\tvalid_set's l2: 0.0218676\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505618\n",
      "[3000]\tvalid_set's l2: 0.0185208\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505363\n",
      "[4000]\tvalid_set's l2: 0.0166996\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50522\n",
      "[5000]\tvalid_set's l2: 0.0155419\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505116\n",
      "[6000]\tvalid_set's l2: 0.0146347\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505036\n",
      "[7000]\tvalid_set's l2: 0.0139264\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504977\n",
      "[8000]\tvalid_set's l2: 0.0134152\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504925\n",
      "[9000]\tvalid_set's l2: 0.0129164\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504883\n",
      "[10000]\tvalid_set's l2: 0.0125734\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5048\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t40.94s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 135.57s of the 135.57s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.00756839\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504322\n",
      "[2000]\tvalid_set's l2: 0.00595825\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504044\n",
      "[3000]\tvalid_set's l2: 0.00538338\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503929\n",
      "[4000]\tvalid_set's l2: 0.00498202\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503863\n",
      "[5000]\tvalid_set's l2: 0.00478316\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503825\n",
      "[6000]\tvalid_set's l2: 0.00462329\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503799\n",
      "[7000]\tvalid_set's l2: 0.00444557\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503778\n",
      "[8000]\tvalid_set's l2: 0.00434167\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503761\n",
      "[9000]\tvalid_set's l2: 0.00428952\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503752\n",
      "[10000]\tvalid_set's l2: 0.00424235\tvalid_set's symmetric_mean_absolute_percentage_error: -0.503739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5037\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t35.16s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 99.77s of the 99.77s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 213 due to low memory. Expected memory usage reduced from 21.09% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 213 -> 209 due to low time. Expected time usage reduced from 101.2s -> 99.8s...\n",
      "\t-0.0006\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t33.65s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 65.74s of the 65.73s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 5720.\n",
      "\t-0.5041\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t65.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.62s of the -0.21s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 1.0}\n",
      "\t-0.0006\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 42405.2 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_potenciaGeradaTG2_1\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       2.99 GB / 15.69 GB (19.0%)\n",
      "Disk Space Avail:   483.64 GB / 929.98 GB (52.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_potenciaGeradaTG2_2\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 14\n",
      "Label Column:       potenciaGeradaTG2_2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3055.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 27.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: potenciaGeradaTG2_2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 12 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.4s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 24.22 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.39s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.61s of the 179.61s of remaining time.\n",
      "\t-0.0119\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.36s of the 178.36s of remaining time.\n",
      "\t-0.0114\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 177.12s of the 177.12s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.0015493\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505734\n",
      "[2000]\tvalid_set's l2: 0.00107438\tvalid_set's symmetric_mean_absolute_percentage_error: -0.505132\n",
      "[3000]\tvalid_set's l2: 0.000888307\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504898\n",
      "[4000]\tvalid_set's l2: 0.000775927\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504762\n",
      "[5000]\tvalid_set's l2: 0.000701411\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504656\n",
      "[6000]\tvalid_set's l2: 0.000645263\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504597\n",
      "[7000]\tvalid_set's l2: 0.000603477\tvalid_set's symmetric_mean_absolute_percentage_error: -0.50453\n",
      "[8000]\tvalid_set's l2: 0.0005726\tvalid_set's symmetric_mean_absolute_percentage_error: -0.5045\n",
      "[9000]\tvalid_set's l2: 0.000549532\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504459\n",
      "[10000]\tvalid_set's l2: 0.000527337\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5044\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t34.41s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 142.0s of the 142.0s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.000459512\tvalid_set's symmetric_mean_absolute_percentage_error: -0.504093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5041\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t6.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 135.49s of the 135.49s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 200 due to low memory. Expected memory usage reduced from 22.49% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 200 -> 186 due to low time. Expected time usage reduced from 145.4s -> 135.5s...\n",
      "\t-0.5033\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t59.49s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 75.62s of the 75.62s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 5830.\n",
      "\t-0.5039\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t75.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.61s of the -0.22s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist': 1.0}\n",
      "\t-0.0114\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 46979.8 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_potenciaGeradaTG2_2\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       2.69 GB / 15.69 GB (17.1%)\n",
      "Disk Space Avail:   483.11 GB / 929.98 GB (51.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels\\Predictor_vazaoVaporEscape\"\n",
      "Train Data Rows:    259142\n",
      "Train Data Columns: 15\n",
      "Label Column:       vazaoVaporEscape\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2749.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.66 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: vazaoVaporEscape ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', [])   :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 13 | ['vazaoVapor', 'pressaoVapor', 'temperaturaVapor', 'cargaVaporTG1', 'cargaVaporTG2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['habilitaTG1', 'habilitaTG2']\n",
      "\t0.4s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.20 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 256550, Val Rows: 2592\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.58s of the 179.58s of remaining time.\n",
      "\t-0.0046\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 178.16s of the 178.16s of remaining time.\n",
      "\t-0.0044\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 176.66s of the 176.66s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 6.5434\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00298393\n",
      "[2000]\tvalid_set's l2: 4.33902\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00240899\n",
      "[3000]\tvalid_set's l2: 3.46713\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00214287\n",
      "[4000]\tvalid_set's l2: 2.99013\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00198176\n",
      "[5000]\tvalid_set's l2: 2.67227\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00186482\n",
      "[6000]\tvalid_set's l2: 2.43947\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00177356\n",
      "[7000]\tvalid_set's l2: 2.25649\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00170117\n",
      "[8000]\tvalid_set's l2: 2.1225\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00164376\n",
      "[9000]\tvalid_set's l2: 2.01507\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00159401\n",
      "[10000]\tvalid_set's l2: 1.91375\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00154867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0015\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t89.64s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 85.71s of the 85.71s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 3.16449\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00204797\n",
      "[2000]\tvalid_set's l2: 2.19809\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00167636\n",
      "[3000]\tvalid_set's l2: 1.83413\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00151617\n",
      "[4000]\tvalid_set's l2: 1.63773\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00142586\n",
      "[5000]\tvalid_set's l2: 1.5029\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00135827\n",
      "[6000]\tvalid_set's l2: 1.41303\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00131381\n",
      "[7000]\tvalid_set's l2: 1.33882\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00127673\n",
      "[8000]\tvalid_set's l2: 1.2786\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00124043\n",
      "[9000]\tvalid_set's l2: 1.23152\tvalid_set's symmetric_mean_absolute_percentage_error: -0.001214\n",
      "[10000]\tvalid_set's l2: 1.19067\tvalid_set's symmetric_mean_absolute_percentage_error: -0.00119316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.0012\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t45.03s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 40.03s of the 40.02s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 188 due to low memory. Expected memory usage reduced from 23.89% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 188 -> 59 due to low time. Expected time usage reduced from 125.9s -> 40.0s...\n",
      "\t-0.0031\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t24.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 15.33s of the 15.33s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1240.\n",
      "\t-0.0018\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t15.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.58s of the -0.18s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.526, 'LightGBMXT': 0.263, 'CatBoost': 0.158, 'RandomForestMSE': 0.053}\n",
      "\t-0.001\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 180.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2995.7 rows/s (2592 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels\\Predictor_vazaoVaporEscape\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor.fit(train_set, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: consumoEspecificoTG1_1 ...\n",
      "Predicting with TabularPredictor for label: consumoEspecificoTG1_2 ...\n",
      "Predicting with TabularPredictor for label: consumoEspecificoTG2_1 ...\n",
      "Predicting with TabularPredictor for label: consumoEspecificoTG2_2 ...\n",
      "Predicting with TabularPredictor for label: potenciaGeradaTG1_1 ...\n",
      "Predicting with TabularPredictor for label: potenciaGeradaTG1_2 ...\n",
      "Predicting with TabularPredictor for label: potenciaGeradaTG2_1 ...\n",
      "Predicting with TabularPredictor for label: potenciaGeradaTG2_2 ...\n",
      "Predicting with TabularPredictor for label: vazaoVaporEscape ...\n",
      "Predictions:  \n",
      "        consumoEspecificoTG1_1  consumoEspecificoTG1_2  consumoEspecificoTG2_1  \\\n",
      "0                    9.700453                8.846820                0.000000   \n",
      "1                    0.000000                0.000000                6.474423   \n",
      "2                   50.389988                8.576043                7.690220   \n",
      "3                    0.000000                0.000000                4.395918   \n",
      "4                    8.594766                7.942017                4.207080   \n",
      "...                       ...                     ...                     ...   \n",
      "14392                6.397502                8.401907                0.000000   \n",
      "14393                8.409435                7.710455                4.068835   \n",
      "14394                0.000000                0.000000                0.000000   \n",
      "14395               13.957175               10.081243                6.639462   \n",
      "14396                0.000000                0.000000                0.000000   \n",
      "\n",
      "       consumoEspecificoTG2_2  potenciaGeradaTG1_1  potenciaGeradaTG1_2  \\\n",
      "0                    0.000000            15.871953            17.417215   \n",
      "1                   11.977343             0.000000             0.000000   \n",
      "2                   11.560365             2.878715            17.000616   \n",
      "3                   11.392940             0.000000             0.000000   \n",
      "4                   11.688891            15.053790            16.281305   \n",
      "...                       ...                  ...                  ...   \n",
      "14392                0.000000            21.980440            16.784454   \n",
      "14393               11.410264            14.513314            15.797581   \n",
      "14394                0.000000             0.000000             0.000000   \n",
      "14395               12.010814            15.634295            21.713535   \n",
      "14396                0.000000             0.000000             0.000000   \n",
      "\n",
      "       potenciaGeradaTG2_1  potenciaGeradaTG2_2  vazaoVaporEscape  \n",
      "0                 0.000000             0.000000        352.269073  \n",
      "1                 9.305935             3.156406        290.853638  \n",
      "2                11.133024             5.662517        339.053711  \n",
      "3                26.567955             8.263156        430.493347  \n",
      "4                18.550407             4.827596        254.304718  \n",
      "...                    ...                  ...               ...  \n",
      "14392             0.000000             0.000000        269.620819  \n",
      "14393            26.562559             7.590977        266.877502  \n",
      "14394             0.000000             0.000000        518.812134  \n",
      "14395             7.812077             2.918752        249.362701  \n",
      "14396             0.000000             0.000000        323.799072  \n",
      "\n",
      "[14397 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained multilabel predictor from file\n",
    "\n",
    "predictions = multi_predictor.predict(X_test)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: consumoEspecificoTG1_1 ...\n",
      "Evaluating TabularPredictor for label: consumoEspecificoTG1_2 ...\n",
      "Evaluating TabularPredictor for label: consumoEspecificoTG2_1 ...\n",
      "Evaluating TabularPredictor for label: consumoEspecificoTG2_2 ...\n",
      "Evaluating TabularPredictor for label: potenciaGeradaTG1_1 ...\n",
      "Evaluating TabularPredictor for label: potenciaGeradaTG1_2 ...\n",
      "Evaluating TabularPredictor for label: potenciaGeradaTG2_1 ...\n",
      "Evaluating TabularPredictor for label: potenciaGeradaTG2_2 ...\n",
      "Evaluating TabularPredictor for label: vazaoVaporEscape ...\n",
      "{'consumoEspecificoTG1_1': {'symmetric_mean_absolute_percentage_error': -0.000984814098113492, 'root_mean_squared_error': -1.8097305693955579, 'mean_squared_error': -3.2751247338047698, 'mean_absolute_error': -0.08314428241326301, 'r2': 0.9831010392146552, 'pearsonr': 0.9915561692919219, 'median_absolute_error': -0.00027329772949258313}, 'consumoEspecificoTG1_2': {'symmetric_mean_absolute_percentage_error': -1.295777402312473e-06, 'root_mean_squared_error': -0.0005729028361853504, 'mean_squared_error': -3.2821765970921835e-07, 'mean_absolute_error': -2.6191601622302067e-05, 'r2': 0.9999999856377444, 'pearsonr': 0.99999999282054, 'median_absolute_error': -6.164551535903229e-09}, 'consumoEspecificoTG2_1': {'symmetric_mean_absolute_percentage_error': -0.0009415528061574175, 'root_mean_squared_error': -0.05994745718404591, 'mean_squared_error': -0.003593697622833018, 'mean_absolute_error': -0.011773887509785254, 'r2': 0.9995416808266017, 'pearsonr': 0.9997732774815253, 'median_absolute_error': -0.0}, 'consumoEspecificoTG2_2': {'symmetric_mean_absolute_percentage_error': -0.0001628170824267301, 'root_mean_squared_error': -0.02343061653307656, 'mean_squared_error': -0.0005489937911200807, 'mean_absolute_error': -0.0037212824728355613, 'r2': 0.9999838481022502, 'pearsonr': 0.9999919388057383, 'median_absolute_error': -0.0}, 'potenciaGeradaTG1_1': {'symmetric_mean_absolute_percentage_error': -0.0010577734848833849, 'root_mean_squared_error': -0.06376012199030842, 'mean_squared_error': -0.004065353156219012, 'mean_absolute_error': -0.03070740414107057, 'r2': 0.9999735668423947, 'pearsonr': 0.9999868066210023, 'median_absolute_error': -0.0004561943359391307}, 'potenciaGeradaTG1_2': {'symmetric_mean_absolute_percentage_error': -3.2579370276938597e-06, 'root_mean_squared_error': -0.002629015068435501, 'mean_squared_error': -6.911720230060922e-06, 'mean_absolute_error': -0.00014313657194258488, 'r2': 0.9999999325997351, 'pearsonr': 0.9999999663125525, 'median_absolute_error': -6.071777356453367e-07}, 'potenciaGeradaTG2_1': {'symmetric_mean_absolute_percentage_error': -0.002642257776727377, 'root_mean_squared_error': -0.264997599995329, 'mean_squared_error': -0.0702237280032844, 'mean_absolute_error': -0.05933090722816978, 'r2': 0.9991557510509756, 'pearsonr': 0.9995789414649235, 'median_absolute_error': -0.0}, 'potenciaGeradaTG2_2': {'symmetric_mean_absolute_percentage_error': -0.011697396742522757, 'root_mean_squared_error': -0.16102015770158712, 'mean_squared_error': -0.02592749118624399, 'mean_absolute_error': -0.07559470493530193, 'r2': 0.9971466002375357, 'pearsonr': 0.9985815414722228, 'median_absolute_error': -0.0}, 'vazaoVaporEscape': {'symmetric_mean_absolute_percentage_error': -0.0011877754266251537, 'root_mean_squared_error': -1.0937553225910652, 'mean_squared_error': -1.1963007056962853, 'mean_absolute_error': -0.7546469185934732, 'r2': 0.9997519229546664, 'pearsonr': 0.9998764315783352, 'median_absolute_error': -0.5464938300781341}}\n",
      "Evaluated using metrics: {'consumoEspecificoTG1_1': 'symmetric_mean_absolute_percentage_error', 'consumoEspecificoTG1_2': 'symmetric_mean_absolute_percentage_error', 'consumoEspecificoTG2_1': 'symmetric_mean_absolute_percentage_error', 'consumoEspecificoTG2_2': 'symmetric_mean_absolute_percentage_error', 'potenciaGeradaTG1_1': 'symmetric_mean_absolute_percentage_error', 'potenciaGeradaTG1_2': 'symmetric_mean_absolute_percentage_error', 'potenciaGeradaTG2_1': 'symmetric_mean_absolute_percentage_error', 'potenciaGeradaTG2_2': 'symmetric_mean_absolute_percentage_error', 'vazaoVaporEscape': 'symmetric_mean_absolute_percentage_error'}\n"
     ]
    }
   ],
   "source": [
    "evaluations = multi_predictor.evaluate(test_set)\n",
    "print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumoEspecificoTG1_1.symmetric_mean_absolute_percentage_error</th>\n",
       "      <th>consumoEspecificoTG1_1.root_mean_squared_error</th>\n",
       "      <th>consumoEspecificoTG1_1.mean_squared_error</th>\n",
       "      <th>consumoEspecificoTG1_1.mean_absolute_error</th>\n",
       "      <th>consumoEspecificoTG1_1.r2</th>\n",
       "      <th>consumoEspecificoTG1_1.pearsonr</th>\n",
       "      <th>consumoEspecificoTG1_1.median_absolute_error</th>\n",
       "      <th>consumoEspecificoTG1_2.symmetric_mean_absolute_percentage_error</th>\n",
       "      <th>consumoEspecificoTG1_2.root_mean_squared_error</th>\n",
       "      <th>consumoEspecificoTG1_2.mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>potenciaGeradaTG2_2.r2</th>\n",
       "      <th>potenciaGeradaTG2_2.pearsonr</th>\n",
       "      <th>potenciaGeradaTG2_2.median_absolute_error</th>\n",
       "      <th>vazaoVaporEscape.symmetric_mean_absolute_percentage_error</th>\n",
       "      <th>vazaoVaporEscape.root_mean_squared_error</th>\n",
       "      <th>vazaoVaporEscape.mean_squared_error</th>\n",
       "      <th>vazaoVaporEscape.mean_absolute_error</th>\n",
       "      <th>vazaoVaporEscape.r2</th>\n",
       "      <th>vazaoVaporEscape.pearsonr</th>\n",
       "      <th>vazaoVaporEscape.median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-1.809731</td>\n",
       "      <td>-3.275125</td>\n",
       "      <td>-0.083144</td>\n",
       "      <td>0.983101</td>\n",
       "      <td>0.991556</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-3.282177e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997147</td>\n",
       "      <td>0.998582</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-1.093755</td>\n",
       "      <td>-1.196301</td>\n",
       "      <td>-0.754647</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>-0.546494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   consumoEspecificoTG1_1.symmetric_mean_absolute_percentage_error  \\\n",
       "0                                                        -0.000985   \n",
       "\n",
       "   consumoEspecificoTG1_1.root_mean_squared_error  \\\n",
       "0                                       -1.809731   \n",
       "\n",
       "   consumoEspecificoTG1_1.mean_squared_error  \\\n",
       "0                                  -3.275125   \n",
       "\n",
       "   consumoEspecificoTG1_1.mean_absolute_error  consumoEspecificoTG1_1.r2  \\\n",
       "0                                   -0.083144                   0.983101   \n",
       "\n",
       "   consumoEspecificoTG1_1.pearsonr  \\\n",
       "0                         0.991556   \n",
       "\n",
       "   consumoEspecificoTG1_1.median_absolute_error  \\\n",
       "0                                     -0.000273   \n",
       "\n",
       "   consumoEspecificoTG1_2.symmetric_mean_absolute_percentage_error  \\\n",
       "0                                                        -0.000001   \n",
       "\n",
       "   consumoEspecificoTG1_2.root_mean_squared_error  \\\n",
       "0                                       -0.000573   \n",
       "\n",
       "   consumoEspecificoTG1_2.mean_squared_error  ...  potenciaGeradaTG2_2.r2  \\\n",
       "0                              -3.282177e-07  ...                0.997147   \n",
       "\n",
       "   potenciaGeradaTG2_2.pearsonr  potenciaGeradaTG2_2.median_absolute_error  \\\n",
       "0                      0.998582                                       -0.0   \n",
       "\n",
       "   vazaoVaporEscape.symmetric_mean_absolute_percentage_error  \\\n",
       "0                                                  -0.001188   \n",
       "\n",
       "   vazaoVaporEscape.root_mean_squared_error  \\\n",
       "0                                 -1.093755   \n",
       "\n",
       "   vazaoVaporEscape.mean_squared_error  vazaoVaporEscape.mean_absolute_error  \\\n",
       "0                            -1.196301                             -0.754647   \n",
       "\n",
       "   vazaoVaporEscape.r2  vazaoVaporEscape.pearsonr  \\\n",
       "0             0.999752                   0.999876   \n",
       "\n",
       "   vazaoVaporEscape.median_absolute_error  \n",
       "0                               -0.546494  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(evaluations,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model name for each label\n",
    "model_map = {}\n",
    "for label in target:\n",
    "    predictor = multi_predictor.get_predictor(label)\n",
    "    best_model_name = predictor.leaderboard()[predictor.leaderboard()['model'] != 'WeightedEnsemble_L2']['model'].iloc[0]\n",
    "    model_map[label] = best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'consumoEspecificoTG1_1': 'RandomForestMSE',\n",
       " 'consumoEspecificoTG1_2': 'RandomForestMSE',\n",
       " 'consumoEspecificoTG2_1': 'RandomForestMSE',\n",
       " 'consumoEspecificoTG2_2': 'RandomForestMSE',\n",
       " 'potenciaGeradaTG1_1': 'RandomForestMSE',\n",
       " 'potenciaGeradaTG1_2': 'RandomForestMSE',\n",
       " 'potenciaGeradaTG2_1': 'RandomForestMSE',\n",
       " 'potenciaGeradaTG2_2': 'KNeighborsDist',\n",
       " 'vazaoVaporEscape': 'LightGBM'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RandomForestMSE from autogluon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "As the AutoML approach showed that the Random Forest model is the best model for most of the target columns, we decided to train a single Random Forest model for all target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1, random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_jobs=-1, random_state=42, verbose=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=42, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_rf_model.fit(X_train_scaled, y_train, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/light_rf_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(light_rf_model, 'models/light_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = light_rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symetric_mape(A, F):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error (SMAPE) metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.array\n",
    "        Actual values.\n",
    "\n",
    "    F : np.array\n",
    "        Forecasted values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        SMAPE metric value.\n",
    "    \n",
    "    \"\"\"\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler_rf.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scaler\n",
    "joblib.dump(scaler, 'models/scaler_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall metrics:\n",
      "R2: 0.9877542417596251\n",
      "MAPE: 9384521327512.895\n",
      "Symetric MAPE: 1.3095146592858176\n",
      "MSE: 2.845370329345731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Repos\\real-time-process-prediction\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "print('Overall metrics:')\n",
    "print('R2:', r2_score(y_test, y_pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "print('Symetric MAPE:', np.mean(symetric_mape(y_test, y_pred)))\n",
    "print('MSE:', np.mean((y_test - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['consumoEspecificoTG1_1', 'consumoEspecificoTG1_2',\n",
    "           'consumoEspecificoTG2_1', 'consumoEspecificoTG2_2',\n",
    "           'potenciaGeradaTG1_1', 'potenciaGeradaTG1_2',\n",
    "           'potenciaGeradaTG2_1', 'potenciaGeradaTG2_2',\n",
    "           'vazaoVaporEscape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mape</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consumoEspecificoTG1_2</th>\n",
       "      <td>4.183591e-03</td>\n",
       "      <td>0.418133</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.006295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potenciaGeradaTG2_2</th>\n",
       "      <td>1.156621e+13</td>\n",
       "      <td>2.233557</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>0.019510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumoEspecificoTG2_1</th>\n",
       "      <td>1.996693e+13</td>\n",
       "      <td>1.449115</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>0.030902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumoEspecificoTG2_2</th>\n",
       "      <td>2.945339e+13</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.998560</td>\n",
       "      <td>0.048937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potenciaGeradaTG1_2</th>\n",
       "      <td>7.233409e-03</td>\n",
       "      <td>0.721831</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>0.089454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potenciaGeradaTG2_1</th>\n",
       "      <td>2.347416e+13</td>\n",
       "      <td>1.937097</td>\n",
       "      <td>0.998533</td>\n",
       "      <td>0.122005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potenciaGeradaTG1_1</th>\n",
       "      <td>2.040903e-02</td>\n",
       "      <td>1.985988</td>\n",
       "      <td>0.997701</td>\n",
       "      <td>0.353621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vazaoVaporEscape</th>\n",
       "      <td>5.059453e-03</td>\n",
       "      <td>0.505734</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>6.239934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumoEspecificoTG1_1</th>\n",
       "      <td>1.581693e-02</td>\n",
       "      <td>1.554124</td>\n",
       "      <td>0.903524</td>\n",
       "      <td>18.697675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mape     smape        r2        mse\n",
       "consumoEspecificoTG1_2  4.183591e-03  0.418133  0.999725   0.006295\n",
       "potenciaGeradaTG2_2     1.156621e+13  2.233557  0.997853   0.019510\n",
       "consumoEspecificoTG2_1  1.996693e+13  1.449115  0.996059   0.030902\n",
       "consumoEspecificoTG2_2  2.945339e+13  0.980052  0.998560   0.048937\n",
       "potenciaGeradaTG1_2     7.233409e-03  0.721831  0.999128   0.089454\n",
       "potenciaGeradaTG2_1     2.347416e+13  1.937097  0.998533   0.122005\n",
       "potenciaGeradaTG1_1     2.040903e-02  1.985988  0.997701   0.353621\n",
       "vazaoVaporEscape        5.059453e-03  0.505734  0.998706   6.239934\n",
       "consumoEspecificoTG1_1  1.581693e-02  1.554124  0.903524  18.697675"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape = np.array([symetric_mape(y_test[target], y_pred[:, i]) for i, target in enumerate(targets)])\n",
    "mape = np.array([mean_absolute_percentage_error(y_test[target], y_pred[:, i]) for i, target in enumerate(targets)])\n",
    "r_2 = np.array([r2_score(y_test[target], y_pred[:, i]) for i, target in enumerate(targets)])\n",
    "mse = np.array([np.mean((y_test[target] - y_pred[:, i])**2) for i, target in enumerate(targets)])\n",
    "\n",
    "# Create a DataFrame with the MAPE for each target\n",
    "mape_df = pd.DataFrame({'mape': mape, 'smape': smape, 'r2': r_2, 'mse': mse}, index=targets).sort_values('mse')\n",
    "mape_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
